<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Critique生成项目参考论文合集 | Hexo</title><meta name="author" content="Kevin"><meta name="copyright" content="Kevin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="1.SELFCHECK: USING LLMS TO ZERO-SHOT CHECK THEIR OWN STEP-BY-STEP REASONINGIntroduction之前的方法:  尝试通过检查这些逐步解决方案中的错误，使用这些检查来为答案提供置信度分数，并在不同的可能选择之间进行选择使用外部验证模型进行，或者通过对LLM进行少数样本上下文学习，通常需要额外的训练数据或特定领域的示例问题:">
<meta property="og:type" content="article">
<meta property="og:title" content="Critique生成项目参考论文合集">
<meta property="og:url" content="https://kevin236-max.github.io/2024/08/22/Critique%E7%94%9F%E6%88%90%E9%A1%B9%E7%9B%AE%E5%8F%82%E8%80%83%E8%AE%BA%E6%96%87%E5%90%88%E9%9B%86/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="1.SELFCHECK: USING LLMS TO ZERO-SHOT CHECK THEIR OWN STEP-BY-STEP REASONINGIntroduction之前的方法:  尝试通过检查这些逐步解决方案中的错误，使用这些检查来为答案提供置信度分数，并在不同的可能选择之间进行选择使用外部验证模型进行，或者通过对LLM进行少数样本上下文学习，通常需要额外的训练数据或特定领域的示例问题:">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://kevin236-max.github.io/img/avatar.jpg">
<meta property="article:published_time" content="2024-08-22T09:47:39.000Z">
<meta property="article:modified_time" content="2024-10-05T13:14:18.395Z">
<meta property="article:author" content="Kevin">
<meta property="article:tag" content="论文解读">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://kevin236-max.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="https://kevin236-max.github.io/2024/08/22/Critique%E7%94%9F%E6%88%90%E9%A1%B9%E7%9B%AE%E5%8F%82%E8%80%83%E8%AE%BA%E6%96%87%E5%90%88%E9%9B%86/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Critique生成项目参考论文合集',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-10-05 21:14:18'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.1.1"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">43</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">9</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/background.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Hexo"><img class="site-icon" src="/img/avatar.jpg"/><span class="site-name">Hexo</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Critique生成项目参考论文合集</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-08-22T09:47:39.000Z" title="Created 2024-08-22 17:47:39">2024-08-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-10-05T13:14:18.395Z" title="Updated 2024-10-05 21:14:18">2024-10-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86/">大模型推理</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word Count:</span><span class="word-count">3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading Time:</span><span>9mins</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Critique生成项目参考论文合集"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="1-SELFCHECK-USING-LLMS-TO-ZERO-SHOT-CHECK-THEIR-OWN-STEP-BY-STEP-REASONING"><a href="#1-SELFCHECK-USING-LLMS-TO-ZERO-SHOT-CHECK-THEIR-OWN-STEP-BY-STEP-REASONING" class="headerlink" title="1.SELFCHECK: USING LLMS TO ZERO-SHOT CHECK THEIR OWN STEP-BY-STEP REASONING"></a>1.<strong>SELFCHECK: USING LLMS TO ZERO-SHOT CHECK THEIR OWN STEP-BY-STEP REASONING</strong></h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>之前的方法:</p>
<blockquote>
<p>尝试通过检查这些逐步解决方案中的错误，使用这些检查来为答案提供置信度分数，并在不同的可能选择之间进行选择<br>使用外部验证模型进行，或者通过对LLM进行少数样本上下文学习，通常需要额外的训练数据或特定领域的示例<br>问题:<br>在实践中使用不便，并限制了它们在特定领域或数据格式的应用</p>
</blockquote>
<p>现在的方法: 零样本逐步检查器，用于自我识别LLM推理链中的错误</p>
<h3 id="SelfCheck"><a href="#SelfCheck" class="headerlink" title="SelfCheck"></a>SelfCheck</h3><h4 id="selfchecking"><a href="#selfchecking" class="headerlink" title="selfchecking"></a>selfchecking</h4><p>直接要求LLM检查自己的推理在很大程度上是无效的，无论是直接给原始答案或者给CoT推理中的每一步<br>selfcheck的模型可以是actor模型也可以是单独的模型<br>将各个步骤的检查结果合并为整个解决方案的单个置信度分数，为[0, 1]</p>
<p>SelfCheck将每个步骤的检查任务分解为四个阶段：目标提取(概括这一步的目的)、信息收集(确定步骤的前提，过滤掉与当前步骤不相关的信息)、步骤重新生成和结果比较<br>细节观察: 信息收集的时候给出问题，并且进一步对问题进行分解；而在步骤重新生成的时候只给分解的问题信息<br>prompt写法直接看论文中，已经很详细了</p>
<h4 id="result-integration"><a href="#result-integration" class="headerlink" title="result integration"></a>result integration</h4><p>对每一步根据结果比较步骤中得到的3种结果，矛盾-&gt;-1, 不直接相关-&gt;0, 支持-&gt;1，根据公式1可计算置信度得分<br>用这个得分作为解决方案之间投票的权重，加权投票</p>
<h2 id="2-Recursive-Introspection-Teaching-Language-Model-Agents-How-to-Self-Improve"><a href="#2-Recursive-Introspection-Teaching-Language-Model-Agents-How-to-Self-Improve" class="headerlink" title="2.Recursive Introspection: Teaching Language Model Agents How to Self-Improve"></a>2.<strong>Recursive Introspection: Teaching Language Model Agents How to Self-Improve</strong></h2><h3 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h3><p>需要模型掌握的qualities: 产生明确寻求有关任务信息的响应;做出决策并通过思考并在推理时验证它们来改进决策<br>以迭代方式监督学习者自身反应的改进</p>
<p>算法RISE:</p>
<blockquote>
<p>在每次迭代中，我们引导学习者进行按策略部署，并在下一轮中通过对从学习者本身采样获得的多个修订候选运行best-of-N获得更好的响应，或者使用功能更强大的模型的响应，以更方便的为准<br>我们能够构建展示学习者如何在其自己的分布下改进其响应的推出。然后，我们使用奖励加权回归目标对这些数据的学习器进行微调，该目标能够从此类推出的高质量和低质量部分中学习。通过反复重复这个过程，我们能够向LLM灌输一般的自我改进能力</p>
</blockquote>
<h3 id="RISE"><a href="#RISE" class="headerlink" title="RISE"></a>RISE</h3><h4 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h4><p>对于数据$\mathcal{D}={(x_i,{y_i}^*)}$<br>给LLM($\pi_{\theta}$)输入$[x,\hat y_{1:t},p_{1:t}]$，这里$\hat y_{1:t}$是之前的生成的结果，$p_{1:t}$是辅助指令(例如，查找错误并改进响应的指令；或来自环境的附加编译器反馈)<br>优化目标函数:</p>
<script type="math/tex; mode=display">\max_{\pi_\theta} \sum_{i=1}^{N} E_{x,y^* \sim \mathcal{D}, \hat{y}_i \sim \pi_\theta(·|[x, \hat{y}_{1:i-1}, p_{1:i-1}])} \left[ I(\hat{y}_i == y^*) \right]</script><h4 id="具体方法"><a href="#具体方法" class="headerlink" title="具体方法"></a>具体方法</h4><p>把多次生成答案的过程变成MDP</p>
<p>生成数据并且微调的完成流程:<br>步骤一:数据生成<br>展开k轮actor模型生成数据，其中一个MDP有T轮，将state，answer，feedback和reward四个on-policy的量存起来得到数据$\mathcal{D}_{on-policy}$<br>接下来有两种方法distill和self-distill在此基础上改进<br>一种方法是<strong>distill</strong>:使用一个更强的教师模型来生成更强的answer，并且得到不同的reward，注意这里收集的数据都是同步的，得到数据$\mathcal{D}_{on-policy+distill}$<br>另外一种方法是<strong>self-distill</strong>:对于每个时间步t，采样N个结果，并且得到里面reward最高的结果。将该回答和reward打包到下一个时间步t+1的MDP数据中，得到$\mathcal{D}_{on-policy+self-distill}$<br>思考点:为什么self-distill打包到下一步时间步中</p>
<p>步骤二:策略提升<br>执行加权监督回归</p>
<script type="math/tex; mode=display">\max_{\theta} \mathbb{E}_{x_i \sim \tilde{\mathcal{D}}} \left[ \sum_{t=1}^{T} \log \pi_\theta(\tilde{y}_i^t | s_i^t) \cdot \exp\left(\frac{r_i^t}{\tau}\right) \right]</script><p>通过奖励值居中来避免奖励高的问题使用频率更高<br>$\tau$来控制好动作和坏动作的差异</p>
<p>在训练完模型后完整的推理流程:</p>
<blockquote>
<p>对于一个问题进行N个时间步的推理，得到一连串不断修改的答案<br>对于oracle方法（有先验的标准答案或者超级模型），如果答案正确就迭代结束<br>对于非oracle方法，使用前几回合的答案多数投票的自一致性来解决问题<br>大部分评估采取后者<br>细节: 如果出现迭代轮次大于k，就用大小为k的滑动窗口不断储存<br>具体算法内容参考附录C的伪代码</p>
</blockquote>
<h3 id="分析原因"><a href="#分析原因" class="headerlink" title="分析原因"></a>分析原因</h3><h2 id="3-Automatically-Correcting-Large-Language-Models-Surveying-the-landscape-of-diverse-self-correction-strategies"><a href="#3-Automatically-Correcting-Large-Language-Models-Surveying-the-landscape-of-diverse-self-correction-strategies" class="headerlink" title="3.Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies"></a>3.<strong>Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies</strong></h2><p>概述通过反馈纠正LLM的整个过程，考虑5个维度: 纠正什么，反馈的来源是什么，反馈的格式是什么，何时使用反馈，以及如何通过反馈修正模型</p>
<p>三个模型: 语言模型，评价模型，提炼模型<br>四种主要错误类型: 幻觉，不忠实的推理(不符合推理链)，有毒、有偏见和有害的内容(用RLHF对齐)，缺陷的代码<br>两种反馈: 人工反馈和自动反馈，自动反馈包含自我反馈(LLM本身)和外部反馈(来自外部模型)<br>外部反馈包括四种方式: 其他模型，外部工具，外部知识源，外部评估指标</p>
<p>自动反馈两种格式:</p>
<blockquote>
<p>标量值: 用critic model将输入和输出映射到单个分数<br>自然语言反馈，这里应用在文本编辑和代码生成上</p>
</blockquote>
<p>自动反馈修正时机有三类: 训练时校正，生成时校正，事后校正</p>
<h3 id="Training-Time-Correction"><a href="#Training-Time-Correction" class="headerlink" title="Training-Time Correction"></a>Training-Time Correction</h3><p>人类反馈<br>自动化反馈: 外部指标指导和自我训练</p>
<h2 id="4-LARGE-LANGUAGE-MODELS-CANNOT-SELF-CORRECT-REASONING-YET"><a href="#4-LARGE-LANGUAGE-MODELS-CANNOT-SELF-CORRECT-REASONING-YET" class="headerlink" title="4.LARGE LANGUAGE MODELS CANNOT SELF-CORRECT REASONING YET"></a>4.<strong>LARGE LANGUAGE MODELS CANNOT SELF-CORRECT REASONING YET</strong></h2><p>观点: 模型仅依靠其固有能力来纠正其初始回应，而不依赖外部反馈难以自我修正它们的推理<br>悖论: 如果LLM拥有自我纠正的能力，为什么它不在最初的尝试中简单地提供正确的答案呢<br>内在自我纠正的概念: 模型仅根据其固有能力，在没有外部反馈的情况下努力纠正其初始响应<br>之前的论文自我纠正的效果来自于:</p>
<blockquote>
<p>使用<strong>预言机标签</strong>来指导自我校正过程的结果<br>使用多个LLM改进推理，但考虑同等数量的响应，功效也没有超过自一致性</p>
</blockquote>
<p>现有工作问题: 一些现有研究声称自我修正能够改进模型的输出，但实际上这种改进可能是因为初始回应生成时使用的提示不够优化。当在自我修正步骤中使用更加详尽的提示时，模型可能会“纠正”初始回答，但这种纠正实际上可能并不是真正的改进，因为它是基于更加明确或优化的提示信息</p>
<h3 id="LLMS-CANNOT-SELF-CORRECT-REASONING-INTRINSICALLY"><a href="#LLMS-CANNOT-SELF-CORRECT-REASONING-INTRINSICALLY" class="headerlink" title="LLMS CANNOT SELF-CORRECT REASONING INTRINSICALLY"></a>LLMS CANNOT SELF-CORRECT REASONING INTRINSICALLY</h3><p>使用的数据集中，现有的带有预言标签的自我修正方法已显示出显着的性能改进<br>采用三步提示策略进行自我修正：提示模型进行初始生成;提示模型回顾前一个答案并产生反馈;通过反馈提示模型再次回答原来的问题<br>在有oracle的情况下，有提升，没有oracle性能会下降</p>
<h3 id="MULTI-AGENT-DEBATE-DOES-NOT-OUTPERFORM-SELF-CONSISTENCY"><a href="#MULTI-AGENT-DEBATE-DOES-NOT-OUTPERFORM-SELF-CONSISTENCY" class="headerlink" title="MULTI-AGENT DEBATE DOES NOT OUTPERFORM SELF-CONSISTENCY"></a>MULTI-AGENT DEBATE DOES NOT OUTPERFORM SELF-CONSISTENCY</h3><p>与其将多智能体辩论标记为“辩论”或“批评”的一种形式，不如将其视为跨多个模型代实现“一致性”的一种手段<br>从根本上来说，它的概念反映了自我一致性的概念<br>区别在于投票机制，投票是模型驱动的还是纯粹基于计数</p>
<h3 id="PROMPT-DESIGN-ISSUES-IN-SELF-CORRECTION-EVALUATION"><a href="#PROMPT-DESIGN-ISSUES-IN-SELF-CORRECTION-EVALUATION" class="headerlink" title="PROMPT DESIGN ISSUES IN SELF-CORRECTION EVALUATION"></a>PROMPT DESIGN ISSUES IN SELF-CORRECTION EVALUATION</h3><p>这里强调正确的提示设计在生成初始LLM响应中的重要性，以公平地衡量自我纠正所实现的绩效改进</p>
<h3 id="conclusion"><a href="#conclusion" class="headerlink" title="conclusion"></a>conclusion</h3><p>利用外部反馈进行纠正<br>根据具有可比较的推理成本的基线评估自我校正<br>设计提示词</p>
<h2 id="5-Generative-Verifiers-Reward-Modeling-as-Next-Token-Prediction"><a href="#5-Generative-Verifiers-Reward-Modeling-as-Next-Token-Prediction" class="headerlink" title="5.Generative Verifiers: Reward Modeling as Next-Token Prediction"></a>5.<strong>Generative Verifiers: Reward Modeling as Next-Token Prediction</strong></h2><p>之前的方法: 基于LLM的验证器通常被训练为判别分类器来对解决方案进行评分，但它们不利用预训练的LLM的文本生成功能<br>提出的方法: 与指令调优无缝集成，支持思想链推理，并且可以通过多数投票利用额外的推理时间计算来实现更好的验证？</p>
<p>好处: 在推理过程中，验证者分数是通过提取“是”令牌的概率来获得的，同时可以利用Cot的llm文本生成器的功能</p>
<p>训练方法:<br>先用yes或者no的二元交叉熵来计算<br>验证解决方案的正确性(verify数据集)与生成正确的解决方案(correct数据集)两个加权在一起做sft<br>其中verify数据的验证有两种选择，直接询问和先cot生成再进行判断</p>
<h2 id="6-RL4F-Generating-Natural-Language-Feedback-with-Reinforcement-Learning-for-Repairing-Model-Outputs"><a href="#6-RL4F-Generating-Natural-Language-Feedback-with-Reinforcement-Learning-for-Repairing-Model-Outputs" class="headerlink" title="6.RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs"></a>6.<strong>RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs</strong></h2><p>使用小模型作为critique model，GPT3为actor model，使用Direct-Refinement作为基线(即在没有自生成批评的情况下提示语言模型直接修复自己的答案)<br>ROUGE:<br>R1 (Recall under 1-gram overlap): 计算的是模型生成的摘要中单词与参考摘要中单词重叠的比例。这个指标关注的是模型生成的摘要能够覆盖多少参考摘要中的内容。<br>R2 (Recall under 2-gram overlap): 类似于R1，但是关注的是重叠的连续两个词的比例，这能够更好地捕捉模型生成摘要的连贯性。<br>RL (Recall under longest common subsequence): 基于最长公共子序列来计算召回率，这能够更全面地评估模型生成的摘要与参考摘要之间的相似度。<br>对于结果和标答进行对比得到的奖励值，这里使用ROUGE这个衡量文本相似度的奖励函数指标，得到奖励值代入PPO的计算中</p>
<p>当然这里只有最后的结果的奖励，或许可以应用deepspeed-chat这里对于reward model的设置，这里具体的实现方法需要看一下代码</p>
<p>这里测试的任务包含: Action Planning, Topic-Based Summarization, Alphabetization<br>附录中对应这些任务的提示词的写法可以看看</p>
<h2 id="7-CRITIQUE-OUT-LOUD-REWARD-MODELS"><a href="#7-CRITIQUE-OUT-LOUD-REWARD-MODELS" class="headerlink" title="7.CRITIQUE-OUT-LOUD REWARD MODELS"></a>7.<strong>CRITIQUE-OUT-LOUD REWARD MODELS</strong></h2><p>之前的方法: 一般奖励模型被训练为简单的基于 LLM 的用户提示和助理响应的分类器<br>LLM-as-a-Judge框架借助偏好能力，但在成对偏好分类上表现不佳<br>CLoud方法: 将传统奖励模型和LLM-as-a-Judge结合<br>{prompt,answer,oracle critique}打包做sft训练，并且根据BT preference model生成标量奖励</p>
<h2 id="8-LARGE-LANGUAGE-MODELS-CANNOT-SELF-CORRECT-REASONING-YET"><a href="#8-LARGE-LANGUAGE-MODELS-CANNOT-SELF-CORRECT-REASONING-YET" class="headerlink" title="8.LARGE LANGUAGE MODELS CANNOT SELF-CORRECT REASONING YET"></a>8.<strong>LARGE LANGUAGE MODELS CANNOT SELF-CORRECT REASONING YET</strong></h2><p>重点: 提供有关推理错误的细粒度反馈</p>
<h3 id="REFINER框架"><a href="#REFINER框架" class="headerlink" title="REFINER框架"></a>REFINER框架</h3><p>三种自然语言推理任务:</p>
<blockquote>
<p>数学应用题<br>综合自然语言推理(使用封闭世界规则和事实生成)<br>道德故事的道德规范和行为生成</p>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://kevin236-max.github.io">Kevin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://kevin236-max.github.io/2024/08/22/Critique%E7%94%9F%E6%88%90%E9%A1%B9%E7%9B%AE%E5%8F%82%E8%80%83%E8%AE%BA%E6%96%87%E5%90%88%E9%9B%86/">https://kevin236-max.github.io/2024/08/22/Critique%E7%94%9F%E6%88%90%E9%A1%B9%E7%9B%AE%E5%8F%82%E8%80%83%E8%AE%BA%E6%96%87%E5%90%88%E9%9B%86/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/">论文解读</a></div><div class="post_share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/10/05/test-time-scaling%E8%B0%83%E7%A0%94/" title="test time scaling调研"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">test time scaling调研</div></div></a></div><div class="next-post pull-right"><a href="/2024/08/02/Evaluating-Mathematical-Reasoning-of-LLM%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="Evaluating Mathematical Reasoning of LLM论文解读"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next</div><div class="next_info">Evaluating Mathematical Reasoning of LLM论文解读</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2024/07/24/ChatGLM-Math%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="ChatGLM-Math论文解读"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-24</div><div class="title">ChatGLM-Math论文解读</div></div></a></div><div><a href="/2024/07/30/DeepSeekMath%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="DeepSeekMath论文解读"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-30</div><div class="title">DeepSeekMath论文解读</div></div></a></div><div><a href="/2024/08/02/Evaluating-Mathematical-Reasoning-of-LLM%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="Evaluating Mathematical Reasoning of LLM论文解读"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-02</div><div class="title">Evaluating Mathematical Reasoning of LLM论文解读</div></div></a></div><div><a href="/2024/07/26/GPT-4-Code-Interpreter%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="GPT-4 Code Interpreter论文解读"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-26</div><div class="title">GPT-4 Code Interpreter论文解读</div></div></a></div><div><a href="/2024/07/13/Measuring-Faithfulness-in-CoT-Reasoning%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="Measuring Faithfulness in CoT Reasoning论文解读"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-13</div><div class="title">Measuring Faithfulness in CoT Reasoning论文解读</div></div></a></div><div><a href="/2024/07/25/OpenMathInstruct-1%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="OpenMathInstruct-1论文解读"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-25</div><div class="title">OpenMathInstruct-1论文解读</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Kevin</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">43</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">9</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://kevin236-max.github.io/" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-SELFCHECK-USING-LLMS-TO-ZERO-SHOT-CHECK-THEIR-OWN-STEP-BY-STEP-REASONING"><span class="toc-number">1.</span> <span class="toc-text">1.SELFCHECK: USING LLMS TO ZERO-SHOT CHECK THEIR OWN STEP-BY-STEP REASONING</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Introduction"><span class="toc-number">1.1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SelfCheck"><span class="toc-number">1.2.</span> <span class="toc-text">SelfCheck</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#selfchecking"><span class="toc-number">1.2.1.</span> <span class="toc-text">selfchecking</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#result-integration"><span class="toc-number">1.2.2.</span> <span class="toc-text">result integration</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Recursive-Introspection-Teaching-Language-Model-Agents-How-to-Self-Improve"><span class="toc-number">2.</span> <span class="toc-text">2.Recursive Introspection: Teaching Language Model Agents How to Self-Improve</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Introduction-1"><span class="toc-number">2.1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RISE"><span class="toc-number">2.2.</span> <span class="toc-text">RISE</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80"><span class="toc-number">2.2.1.</span> <span class="toc-text">基础</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E6%96%B9%E6%B3%95"><span class="toc-number">2.2.2.</span> <span class="toc-text">具体方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%9E%90%E5%8E%9F%E5%9B%A0"><span class="toc-number">2.3.</span> <span class="toc-text">分析原因</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Automatically-Correcting-Large-Language-Models-Surveying-the-landscape-of-diverse-self-correction-strategies"><span class="toc-number">3.</span> <span class="toc-text">3.Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Training-Time-Correction"><span class="toc-number">3.1.</span> <span class="toc-text">Training-Time Correction</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-LARGE-LANGUAGE-MODELS-CANNOT-SELF-CORRECT-REASONING-YET"><span class="toc-number">4.</span> <span class="toc-text">4.LARGE LANGUAGE MODELS CANNOT SELF-CORRECT REASONING YET</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#LLMS-CANNOT-SELF-CORRECT-REASONING-INTRINSICALLY"><span class="toc-number">4.1.</span> <span class="toc-text">LLMS CANNOT SELF-CORRECT REASONING INTRINSICALLY</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MULTI-AGENT-DEBATE-DOES-NOT-OUTPERFORM-SELF-CONSISTENCY"><span class="toc-number">4.2.</span> <span class="toc-text">MULTI-AGENT DEBATE DOES NOT OUTPERFORM SELF-CONSISTENCY</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PROMPT-DESIGN-ISSUES-IN-SELF-CORRECTION-EVALUATION"><span class="toc-number">4.3.</span> <span class="toc-text">PROMPT DESIGN ISSUES IN SELF-CORRECTION EVALUATION</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#conclusion"><span class="toc-number">4.4.</span> <span class="toc-text">conclusion</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Generative-Verifiers-Reward-Modeling-as-Next-Token-Prediction"><span class="toc-number">5.</span> <span class="toc-text">5.Generative Verifiers: Reward Modeling as Next-Token Prediction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-RL4F-Generating-Natural-Language-Feedback-with-Reinforcement-Learning-for-Repairing-Model-Outputs"><span class="toc-number">6.</span> <span class="toc-text">6.RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-CRITIQUE-OUT-LOUD-REWARD-MODELS"><span class="toc-number">7.</span> <span class="toc-text">7.CRITIQUE-OUT-LOUD REWARD MODELS</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-LARGE-LANGUAGE-MODELS-CANNOT-SELF-CORRECT-REASONING-YET"><span class="toc-number">8.</span> <span class="toc-text">8.LARGE LANGUAGE MODELS CANNOT SELF-CORRECT REASONING YET</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#REFINER%E6%A1%86%E6%9E%B6"><span class="toc-number">8.1.</span> <span class="toc-text">REFINER框架</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/10/17/%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E4%BF%AE%E6%94%B9%E8%AE%BA%E6%96%87%E5%90%88%E9%9B%86/" title="模型架构修改论文合集">模型架构修改论文合集</a><time datetime="2024-10-17T02:30:31.000Z" title="Created 2024-10-17 10:30:31">2024-10-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/10/14/flow-matching-rlhf%E9%A1%B9%E7%9B%AE%E5%8F%82%E8%80%83%E8%AE%BA%E6%96%87%E5%90%88%E9%9B%86/" title="flow matching rlhf项目参考论文合集">flow matching rlhf项目参考论文合集</a><time datetime="2024-10-14T12:48:11.000Z" title="Created 2024-10-14 20:48:11">2024-10-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/10/13/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%85%A5%E9%97%A8/" title="多模态入门">多模态入门</a><time datetime="2024-10-13T04:22:09.000Z" title="Created 2024-10-13 12:22:09">2024-10-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/10/12/%E5%9B%BE%E7%89%87%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95%E8%B0%83%E7%A0%94/" title="图片生成算法调研">图片生成算法调研</a><time datetime="2024-10-12T12:43:17.000Z" title="Created 2024-10-12 20:43:17">2024-10-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/10/05/test-time-scaling%E8%B0%83%E7%A0%94/" title="test time scaling调研">test time scaling调研</a><time datetime="2024-10-05T13:17:06.000Z" title="Created 2024-10-05 21:17:06">2024-10-05</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Kevin</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>